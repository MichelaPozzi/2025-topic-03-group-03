---
title: "Data Reduction"
output: html_document
date: "2025-05-31"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
MS_Table_norm = read.table("Datensätze/MS_Table.norm.csv", header=TRUE, row.names=1, sep = ",")
```

# PCA

```{r}
# PCA mit ursprünglichen Werten
# nur Carls Code

pca = prcomp(MS_Table, center = FALSE, scale = FALSE)
summary(pca)
pca$sdev
variance = (pca$sdev)^2
prop.variance = variance/sum(variance)
names(prop.variance) = 1:length(prop.variance)
barplot(prop.variance[1:20],ylab='Proportion of variance') # we only plot the first 20 PCs

plot(pca$x[,1], pca$x[,2], 
     col= 'black', pch=19,
     xlab='PC1',ylab='PC2')
```

```{r}
# PCA mit normierten Werten
# nur Carls Code

pca = prcomp(MS_Table_norm, center = FALSE, scale = FALSE)
summary(pca)
pca$sdev
variance = (pca$sdev)^2
prop.variance = variance/sum(variance)
names(prop.variance) = 1:length(prop.variance)
barplot(prop.variance[1:20],ylab='Proportion of variance') # we only plot the first 20 PCs

plot(pca$x[,1], pca$x[,2], 
     col= 'black', pch=19,
     xlab='PC1',ylab='PC2')
```
## Installieren der genannten libraries im Code 
```{r install_all_needed, eval=FALSE}
install.packages(c("factoextra", "cluster", "pheatmap", "RColorBrewer"))
# Für Elbow- und Silhouette-Methode => library(factoextra)
# Für Silhouette-Plot => library(cluster)
# Für Heatmaps => library(pheatmap)
# Für schöne Farben in Plots => library(RColorBrewer)   
```


## K-Means Clustering auf die obigen PCA-Ergebnissen angewandt 

```{r kmeans_pca_clustering, message=FALSE, warning=FALSE}

# PCA auf normierter Tabelle
pca = prcomp(MS_Table_norm, center = TRUE, scale. = TRUE)

# Varianz-Anteile anzeigen (optional)
prop.variance = (pca$sdev)^2 / sum(pca$sdev^2)
barplot(prop.variance[1:10], main = "Varianzanteile (Top 10 PCs)", ylab = "Proportion")

# Auswahl der ersten 5 Hauptkomponenten für Clustering
pca_data = pca$x[, 1:5]

# Benötigte Pakete laden
library(factoextra)
library(cluster)
library(RColorBrewer)
col = brewer.pal(9, 'Set1')

# Elbow-Methode(Zusatzt Linie zum Knickpunkt) => Verändert
elbow_plot <- fviz_nbclust(pca_data, kmeans, method = "wss") +
  ggtitle("Elbow-Methode – optimale Clusteranzahl") +
  geom_vline(xintercept = 5, linetype = 2, color = "blue")  # Code bestimmt trz. nicht optimales k => muss selber bei "x-intercept" eingesetzt werden

print(elbow_plot)

# Silhouette-Methode
fviz_nbclust(pca_data, kmeans, method = "silhouette") +
  ggtitle("Silhouette-Methode – optimale Clusteranzahl")

# Setze Seed für Reproduzierbarkeit
set.seed(123)

# K-Means Clustering mit k = 3 ==> eventuell muss noch angepasst werden
km = kmeans(pca_data, centers = 6, nstart = 25)

# Cluster-Zuordnung speichern
cluster_assignment = km$cluster

# Plot der ersten zwei PCs mit Clusterfarben
plot(pca$x[,1], pca$x[,2],
     col = col[cluster_assignment],
     pch = 19,
     xlab = "PC1", ylab = "PC2",
     main = "K-Means Clustering auf PCA (k=3)")

# Erstellung Silhouette Plots zur Bewertung der Clusterqualität => Verändert

# Silhouette-Plot (so, dass wenn der Datensatz zu groß ist eine Stichprobe erstellt wird)

library(factoextra)

# Prüfen ob Datensatz zu groß ist (> 1000 Beobachtungen)
n_obs <- nrow(pca_data)
sample_threshold <- 1000  #bestimmt ab wann Stichprobe gemacht werden sollte

if (n_obs > sample_threshold) {
  # Stichprobe ziehen
  set.seed(42)
  sample_idx <- sample(1:n_obs, 500)  # Größe der Stichprobe wird durch zuvorgehenden Code bestimmt 
  pca_sample <- pca_data[sample_idx, ]
  cluster_sample <- cluster_assignment[sample_idx]
  dist_sample <- dist(pca_sample)
  sil <- silhouette(cluster_sample, dist_sample)
  message("Der Silhouette-Plot basiert jetzt auf einer Stichprobe von 500 Beobachtungen")
} else {
  # Verwendung des gesamten Datensatzes 
  dist_matrix <- dist(pca_data)
  sil <- silhouette(cluster_assignment, dist_matrix)
}

# Visualisierung mit factoextra
fviz_silhouette(sil) +
  ggtitle("Silhouette-Plot für K-Means Clustering")


# Export der Cluster-Zuordnung als CSV Datei => später noch notwendig zum Beispiel zur Visualisierung 
cluster_df = data.frame(Sample = colnames(MS_Table_norm),
                        Cluster = cluster_assignment)
write.csv(cluster_df, "Cluster_Zuordnung.csv", row.names = FALSE)
```



## VERSCHIEDENE OPTIONEN DES EINKREISENS => K-Means Clustering auf die obigen PCA-Ergebnissen angewandt 

```{r kmeans_pca_clustering, message=FALSE, warning=FALSE}

# PCA auf normierter Tabelle
pca = prcomp(MS_Table_norm, center = TRUE, scale. = TRUE)

# Varianz-Anteile anzeigen (optional)
prop.variance = (pca$sdev)^2 / sum(pca$sdev^2)
barplot(prop.variance[1:10], main = "Varianzanteile (Top 10 PCs)", ylab = "Proportion")

# Auswahl der ersten 5 Hauptkomponenten für Clustering
pca_data = pca$x[, 1:5]

# Benötigte Pakete laden
library(factoextra)
library(cluster)
library(RColorBrewer)
col = brewer.pal(9, 'Set1')

# Elbow-Methode(Zusatzt Linie zum Knickpunkt) => Verändert
elbow_plot <- fviz_nbclust(pca_data, kmeans, method = "wss") +
  ggtitle("Elbow-Methode – optimale Clusteranzahl") +
  geom_vline(xintercept = 5, linetype = 2, color = "blue")  # Code bestimmt trz. nicht optimales k => muss selber bei "x-intercept" eingesetzt werden

print(elbow_plot)

# Silhouette-Methode
fviz_nbclust(pca_data, kmeans, method = "silhouette") +
  ggtitle("Silhouette-Methode – optimale Clusteranzahl")

# Setze Seed für Reproduzierbarkeit
set.seed(123)

# K-Means Clustering mit k = 3 ==> eventuell muss noch angepasst werden
km = kmeans(pca_data, centers = 6, nstart = 25)

# Cluster-Zuordnung speichern
cluster_assignment = km$cluster

# Plot der ersten zwei PCs mit Clusterfarben
plot(pca$x[,1], pca$x[,2],
     col = col[cluster_assignment],
     pch = 19,
     xlab = "PC1", ylab = "PC2",
     main = "K-Means Clustering auf PCA (k=3)")

# Konvexhüllen für jedes Cluster zeichnen
library(grDevices)  # Für RGB Transparenz

for (k in 1:max(cluster_assignment)) {
  cluster_points <- pca$x[cluster_assignment == k, 1:2]
  
  if (nrow(cluster_points) >= 3) {  # Konvexhülle nur bei >=3 Punkten sinnvoll
    hull_indices <- chull(cluster_points)
    hull_indices <- c(hull_indices, hull_indices[1])  # Hülle schließen
    
polygon(cluster_points[hull_indices, ],
        border = col[k],
        col = adjustcolor(col[k], alpha.f = 0.4),  # Weniger transparent
        lwd = 2)  
    
  }
}

# Erstellung Silhouette Plots zur Bewertung der Clusterqualität => Verändert

# Silhouette-Plot (so, dass wenn der Datensatz zu groß ist eine Stichprobe erstellt wird)

library(factoextra)

# Prüfen ob Datensatz zu groß ist (> 1000 Beobachtungen)
n_obs <- nrow(pca_data)
sample_threshold <- 1000  #bestimmt ab wann Stichprobe gemacht werden sollte

if (n_obs > sample_threshold) {
  # Stichprobe ziehen
  set.seed(42)
  sample_idx <- sample(1:n_obs, 500)  # Größe der Stichprobe wird durch zuvorgehenden Code bestimmt 
  pca_sample <- pca_data[sample_idx, ]
  cluster_sample <- cluster_assignment[sample_idx]
  dist_sample <- dist(pca_sample)
  sil <- silhouette(cluster_sample, dist_sample)
  message("Der Silhouette-Plot basiert jetzt auf einer Stichprobe von 500 Beobachtungen")
} else {
  # Verwendung des gesamten Datensatzes 
  dist_matrix <- dist(pca_data)
  sil <- silhouette(cluster_assignment, dist_matrix)
}

# Visualisierung mit factoextra
fviz_silhouette(sil) +
  ggtitle("Silhouette-Plot für K-Means Clustering")

# Export der Cluster-Zuordnung als CSV Datei => später noch notwendig zum Beispiel zur Visualisierung 
cluster_df = data.frame(Sample = colnames(MS_Table_norm),
                        Cluster = cluster_assignment)
write.csv(cluster_df, "Cluster_Zuordnung.csv", row.names = FALSE)
```

## K-Means Clustering auf die obigen PCA-Ergebnissen angewandt => Wie schwarzen Umkreisungen Größe ändern? => bei stat-eclipse => level  => Zahlenwert anpassen

```{r kmeans_pca_clustering, message=FALSE, warning=FALSE}

# PCA auf normierter Tabelle
pca = prcomp(MS_Table_norm, center = TRUE, scale. = TRUE)

# Varianz-Anteile anzeigen (optional)
prop.variance = (pca$sdev)^2 / sum(pca$sdev^2)
barplot(prop.variance[1:10], main = "Varianzanteile (Top 10 PCs)", ylab = "Proportion")

# Auswahl der ersten 5 Hauptkomponenten für Clustering
pca_data = pca$x[, 1:5]

# Benötigte Pakete laden
library(factoextra)
library(cluster)
library(RColorBrewer)
col = brewer.pal(9, 'Set1')

# Elbow-Methode(Zusatzt Linie zum Knickpunkt) => Verändert
elbow_plot <- fviz_nbclust(pca_data, kmeans, method = "wss") +
  ggtitle("Elbow-Methode – optimale Clusteranzahl") +
  geom_vline(xintercept = 5, linetype = 2, color = "blue")  # Code bestimmt trz. nicht optimales k => muss selber bei "x-intercept" eingesetzt werden

print(elbow_plot)

# Silhouette-Methode
fviz_nbclust(pca_data, kmeans, method = "silhouette") +
  ggtitle("Silhouette-Methode – optimale Clusteranzahl")

# Setze Seed für Reproduzierbarkeit
set.seed(123)

# K-Means Clustering mit k = 3 ==> eventuell muss noch angepasst werden
km = kmeans(pca_data, centers = 6, nstart = 25)

# Cluster-Zuordnung speichern
cluster_assignment = km$cluster

# Plot der ersten zwei PCs mit Clusterfarben
plot(pca$x[,1], pca$x[,2],
     col = col[cluster_assignment],
     pch = 19,
     xlab = "PC1", ylab = "PC2",
     main = "K-Means Clustering auf PCA (k=3)")
library(ggplot2)

# PCA-Daten + Cluster-Zuordnung vorbereiten
plot_data <- data.frame(PC1 = pca$x[,1],
                        PC2 = pca$x[,2],
                        Cluster = factor(cluster_assignment))

# Plot mit Farbgruppen und schwarzen Umrissen
ggplot(plot_data, aes(x = PC1, y = PC2, color = Cluster)) +
  geom_point(alpha = 0.6, size = 1.5) +
  stat_ellipse(aes(group = Cluster), 
               type = "norm",   # oder "t" oder "euclid"
               level = 0.8,     # Nur Kernbereich!
               color = "black", 
               size = 0.8, 
               linetype = "solid") +
  scale_color_manual(values = col) +
  labs(title = "K-Means Clustering auf PCA (k=3)") +
  theme_minimal()

# Erstellung Silhouette Plots zur Bewertung der Clusterqualität => Verändert

# Silhouette-Plot (so, dass wenn der Datensatz zu groß ist eine Stichprobe erstellt wird)

library(factoextra)

# Prüfen ob Datensatz zu groß ist (> 1000 Beobachtungen)
n_obs <- nrow(pca_data)
sample_threshold <- 1000  #bestimmt ab wann Stichprobe gemacht werden sollte

if (n_obs > sample_threshold) {
  # Stichprobe ziehen
  set.seed(42)
  sample_idx <- sample(1:n_obs, 500)  # Größe der Stichprobe wird durch zuvorgehenden Code bestimmt 
  pca_sample <- pca_data[sample_idx, ]
  cluster_sample <- cluster_assignment[sample_idx]
  dist_sample <- dist(pca_sample)
  sil <- silhouette(cluster_sample, dist_sample)
  message("Der Silhouette-Plot basiert jetzt auf einer Stichprobe von 500 Beobachtungen")
} else {
  # Verwendung des gesamten Datensatzes 
  dist_matrix <- dist(pca_data)
  sil <- silhouette(cluster_assignment, dist_matrix)
}

# Durchschnittliche Silhouette-Breiten berechnen (korrekt!)
avg_sil_width <- mean(sil[, "sil_width"])
avg_sil_per_cluster <- tapply(sil[, "sil_width"], sil[, "cluster"], mean)

# Silhouette-Plot generieren
library(ggplot2)
sil_plot <- fviz_silhouette(sil) +
  ggtitle("Silhouette-Plot für K-Means Clustering") +
  theme(plot.title = element_text(hjust = 0.5))

# Anmerkungen erzeugen (als Textblock rechts oben)
label_text <- paste0("Average silhouette width: ", round(avg_sil_width, 3), "\n",
                     paste0("Cluster ", names(avg_sil_per_cluster), ": ",
                            round(avg_sil_per_cluster, 3),
                            collapse = "\n"))

# Plot anzeigen mit Text (via annotate)
sil_plot + 
  annotate("text",
           x = Inf, y = Inf,
           label = label_text,
           hjust = 1.1, vjust = 1.1,
           size = 2.8,
           fontface = "italic")

# Export der Cluster-Zuordnung als CSV Datei => später noch notwendig zum Beispiel zur Visualisierung 
cluster_df = data.frame(Sample = colnames(MS_Table_norm),
                        Cluster = cluster_assignment)
write.csv(cluster_df, "Cluster_Zuordnung.csv", row.names = FALSE)
```

##Plotvisualisierungen für die Data Exploration 
# Heatmap für Replikatenvergleich  
```{r heatmap_replikate}

print(dim(MS_Table_norm))
print(colnames(MS_Table_norm))


# Pakete laden
library(pheatmap)
library(RColorBrewer)

# Definiere die Replikatspalten (aus deinem Clean-Up bekannt)
replikate <- c("Fraction1_Ctrl_Rep1", "Fraction1_Ctrl_Rep2", "Fraction1_Ctrl_Rep3",
               "Fraction1_RNase_Rep1", "Fraction1_RNase_Rep2", "Fraction1_RNase_Rep3")

# Prüfen, welche Spalten fehlen => nur zur Fehlerfindung => wird dannach rausgenommen 
missing <- replikate[!replikate %in% colnames(MS_Table_norm)]
print(missing)

# Subset aus der normierten Matrix
data_for_heatmap <- MS_Table_norm[, replikate]

# Transponieren: Zeilen = Replikate, Spalten = Proteine
data_for_heatmap_t <- t(data_for_heatmap)

# Farben für die Heatmap
heat_colors <- colorRampPalette(brewer.pal(9, "YlGnBu"))(100)

# Heatmap zeichnen
pheatmap(data_for_heatmap_t,
         scale = "row",  # z-Standardisierung der Replikate
         clustering_distance_rows = "euclidean",
         clustering_distance_cols = "euclidean",
         clustering_method = "complete",
         color = heat_colors,
         main = "Heatmap: Vergleich der Replikate (MS_Table_norm)")
```


# Heatmap Proteinverteilung RNAse und Kontrolle im Vergleich 
```{r heatmap_rnase_kontrolle}
# Libraries
library(pheatmap)
library(RColorBrewer)

# Spaltennamen (Proben)
gruppen <- c("Kontrolle", "Kontrolle", "Kontrolle", "RNAse", "RNAse", "RNAse")
names(gruppen) <- c("Fraction1_Ctrl_Rep1", "Fraction1_Ctrl_Rep2", "Fraction1_Ctrl_Rep3",
                    "Fraction1_RNase_Rep1", "Fraction1_RNase_Rep2", "Fraction1_RNase_Rep3")

# Annotation für die Probenfarben
annotation_col <- data.frame(Gruppe = gruppen)
rownames(annotation_col) <- names(gruppen)

# Farben definieren
group_colors <- list(Gruppe = c(Kontrolle = "lightblue", RNAse = "salmon"))

# Optional: Top 50 variabelste Proteine auswählen
top_var <- apply(MS_Table_norm, 1, var)
top50 <- MS_Table_norm[order(top_var, decreasing = TRUE)[1:50], ]

# Heatmap zeichnen
pheatmap(top50,
         scale = "row",
         annotation_col = annotation_col,
         annotation_colors = group_colors,
         clustering_distance_cols = "euclidean",
         clustering_method = "complete",
         color = colorRampPalette(brewer.pal(9, "RdBu"))(100),
         main = "Proteinverteilung: RNAse vs. Kontrolle")
```

## DATA EXPLORATION VISUALISIERUNG  

```{r}
# Index
zeile <- 'EI2BB_HUMAN'

# x-Werte (Fraktionen)
x <- 1:25

# y-Werte
y_control <- Ctrl1_norm[zeile,]
y_rnase <- RNAse1_norm[zeile,]

# Y-Achsen-Limits berechnen
ylim_bereich <- range(c(y_control, y_rnase), na.rm = TRUE)

# Leerer Plot
plot(x, y_control, type = "n",
     xlab = "", ylab = "Protein amount",
     main = expression(bold("Quantitative RNA-dependent shift")),
     ylim = ylim_bereich)

# Grid
grid(nx = 25, ny = 10, col = "lightgray", lty = "solid")

# Fläche RNase (rot, links)
polygon(c(x, rev(x)), c(y_rnase, rep(0, length(x))),
        col = rgb(255, 0, 0, 80, maxColorValue = 255),  # Transparenz
        border = NA)

# Fläche Control (grün, rechts)
polygon(c(x, rev(x)), c(y_control, rep(0, length(x))),
        col = rgb(0, 255, 0, 50, maxColorValue = 255),
        border = NA)

# Linien
lines(x, y_rnase, col = "red", lwd = 2)
lines(x, y_control, col = "green4", lwd = 2)

# Prozentwerte
text(x[which.max(y_rnase)], max(y_rnase) * 0.9, "95%", col = "black", font = 2, cex = 1.2)
text(x[which.max(y_control)], max(y_control) * 0.9, "85%", col = "black", font = 2, cex = 1.2)

# Pfeil (von RNase zu Control)
arrows(x0 = which.max(y_rnase), y0 = max(y_rnase) + 0.02,
       x1 = which.max(y_control), y1 = max(y_control) + 0.02,
       length = 0.1, lwd = 2, col = "black")

# Legende
legend("topright", legend = c("Control", "RNase"),
       col = c("green4", "red"), lty = 1, lwd = 2, bty = "n", cex = 0.9)
```

```{r}
df_ergebnisse
```



